<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ivan Koptiev - Machine & Deep Learning Portfolio</title>
    <link rel="stylesheet" href="styles.css?v=3">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>

<body>
    <!-- Header Section with Photo and Contact Info -->
    <header>
        <div class="header-content">
            <div class="profile-section">
                <img src="images/me.jpg" alt="Ivan Koptiev" class="profile-photo">
                <div class="profile-info">
                    <h1>Ivan Koptiev</h1>
                    <p class="title">Machine and Deep Learning Engineer</p>
                    <p class="current-role">ML Intern at SERP AI — Aug 2025–Present</p>
                    <div class="contact-info">
                        <p><i class="fas fa-map-marker-alt"></i> Rhode Island, USA</p>
                        <p><i class="fas fa-envelope"></i> koptew.ivan@gmail.com</p>
                    </div>
                    <div class="profile-social-links" style="margin-top:1.5rem; display:flex; justify-content:center; gap:1rem;">
                        <a href="https://github.com/Ivan-Koptiev" target="_blank" class="profile-social-btn github"><i class="fab fa-github"></i>GitHub</a>
                        <a href="https://www.linkedin.com/in/ivan-koptiev-87ab1a298/" target="_blank" class="profile-social-btn linkedin"><i class="fab fa-linkedin"></i>LinkedIn</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="sticky-nav">
        <a href="#about-me">About Me</a>
        <a href="#experience">Experience</a>
        <a href="#major-projects">Projects</a>
        <a href="#contact">Contact</a>
    </nav>

    <!-- About Me Section -->
    <section id="about-me">
        <h2>About Me</h2>
        <div class="about-content">
            <div class="about-text">
                <ul style="color:#e0e7ef; font-size:1.13rem; font-weight:500; margin-bottom:1.5rem;">
                    <li><strong>Currently:</strong> Machine Learning Intern at SERP AI (Aug 2025–Present) building an open boxing dataset for punch recognition, and managing other 
                        members of the annotation team. Check out project's github page for more info: <a href="https://github.com/serp-ai/boxing-punch-recognition-dataset">Project</a></li>
                    <li>High school senior based in Rhode Island, USA, passionate about <strong>Machine
                        Learning</strong> and <strong>Deep Learning</strong>.</li>
                    <li>Interested in building and experimenting with AI models to solve real-world problems and always
                        eager to learn new techniques and technologies.</li>
                    <li>Main programming language: <strong>Python</strong> (regularly use TensorFlow, PyTorch, NumPy,
                        Pandas, SciKit-Learn, matplotlib).</li>
                    <li>Experience with <strong>SQL</strong> for data management; Learned <strong>Java</strong> and exploring basics of
                        <strong>C++</strong> to broaden programming skills.</li>
                    <li>Favorite projects include CNN for classifying flowers, GAN for genertating fashion pieces, and NLP applications like 
                        BERT fine-tuning for sentiment analysis and text classification.</li>
                    <li>Active on <a href="https://www.deep-ml.com">deep-ml.com</a>(User name: Ivan Koptiev) Currently at 70% problems solved!
                        Also active on deep-ml discord community(my discord username: 1satix1), always open for collaboration and new experiences!</li>
                    <li>I am also a creator of a discord server for studying and learning about AI, Machine Learning, and Deep Learning called "Study AI Together".
                        I post guides, resources, courses, etc there, and it's a place for people to ask questions, discuss, and study together or even work on problems together.
                        Everybody is welcome to join, here is the link: <a href="https://discord.gg/ccFmhbXK">Study AI Together</a>.</li>
                    <li>Enjoy running and working out to maintain a healthy and balanced lifestyle.</li>
                    <li><strong>Actively seeking internship opportunities in AI/ML</strong> or any type of experience in the industry to grow. 
                        Open to collaboration and advice!</li>
                </ul>
            </div>
            <div class="skills">
                <h3>Technical Skills</h3>
                <div class="skill-tags">
                    <span>Python (main)</span>
                    <span>TensorFlow</span>
                    <span>PyTorch</span>
                    <span>NumPy</span>
                    <span>Pandas</span>
                    <span>Matplotlib</span>
                    <span>SQL</span>
                    <span>Machine Learning</span>
                    <span>Deep Learning</span>
                    <span>Artificial Intelligence</span>
                    <span>Natural Language Processing(NLP)</span>
                    <span>Java (intermediate)</span>
                    <span>C++ (basic)</span>
                </div>
            </div>
            <div class="skills">
                <h3>Languages</h3>
                <div class="skill-tags">
                    <span>Russian</span>
                    <span>Ukrainian</span>
                    <span>English (fluent)</span>
                    <span>Italian (~B1)</span>
                    <span>French (~A2)</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Experience Section -->
    <section id="experience">
        <h2>Experience</h2>
        <div class="projects-grid">
            <div class="project-card">
                <h3>Machine Learning Intern — SERP AI</h3>
                <div class="preview">
                    <p>
                        Building an open, real‑time boxing punch dataset and tracking pipeline. Aug 2025 — Present.
                    </p>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Description:</strong><br>
                    SERP AI is teaming up with Boxing Undefeated to create the first open, comprehensive boxing dataset focused on punch recognition and classification. We are labeling boxing match videos to power future ML models for real-time, open-source punch tracking and analytics for gyms, trainers, analysts, and fans.
                    </p>
                    <ul>
                        <li>Direct impact on the boxing community</li>
                        <li>Experience with annotation tools, dataset creation, model training, and team/project management</li>
                        <li>Contribution to a real world project</li>
                    </ul>
                    <ul>
                        <li>Responsibilities: video annotation, label punches and boxers, quality control, preparing data for model training, managing annotation team.</li>
                    </ul>
                    <p><strong>Status:</strong> Active
                       <strong>Start date:</strong> August 2025
                    </p>
                </div>
            </div>
        </div>
    </section>
    
    <!-- Major Projects Section -->
    <section id="major-projects">
        <h2>Projects</h2>
        <div class="projects-grid">

            <!-- Project: News Category Text Classification with N-grams -->
            <div class="project-card">
                <h3>News Category Text Classification with N-grams</h3>
                <div class="preview">
                    <p>
                        Classifying news articles using n-gram features and comparing multiple ML models.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/ngram-text_classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built a text classification pipeline for news articles using bag-of-words and n-gram features. Compared LinearSVC, XGBoost, and AdaBoost models. LinearSVC achieved <b>86.9% accuracy</b>, outperforming the others. Visualizations include class distribution and model comparison.
                    </p>
                    <img src="images/NLP_n_grams/original_class_distribution.png" alt="Class Distribution" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/NLP_n_grams/model_comparison.png" alt="Model Comparison" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: News articles (4 categories, balanced)</li>
                        <li>Techniques: NLTK preprocessing, n-grams, model comparison</li>
                        <li>Key learning: LinearSVC is highly effective for n-gram text classification</li>
                    </ul>
                    <strong>What I learned:</strong> Preprocessing and model selection are crucial for NLP success.
                    <a href="https://github.com/Ivan-Koptiev/ngram-text_classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Image Classification with CNN on CIFAR-10 -->
            <div class="project-card">
                <h3>Image Classification with CNN on CIFAR-10</h3>
                <div class="preview">
                    <p>
                        Building and training a CNN for CIFAR-10 image classification with data augmentation.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/CNN_cifar10" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Developed a deep convolutional neural network to classify images from the CIFAR-10 dataset. The model uses batch normalization, dropout, and real-time data augmentation to improve generalization. Achieved <b>82.8% accuracy</b> and <b>83.8% validation accuracy</b> after 50 epochs.
                    </p>
                    <img src="images/CNN_cifar10/model_performance.png" alt="Model Performance" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/CNN_cifar10/predictions.png" alt="Predictions Grid" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: CIFAR-10 (60,000 images, 10 classes)</li>
                        <li>Techniques: Batch normalization, dropout, data augmentation</li>
                        <li>Key learning: Regularization and visualization are essential for deep learning success</li>
                    </ul>
                    <strong>What I learned:</strong> Data augmentation and regularization are key to high-performing image classifiers.
                    <a href="https://github.com/Ivan-Koptiev/CNN_cifar10" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Wine Classification with K-Nearest Neighbors -->
            <div class="project-card">
                <h3>Wine Classification with K-Nearest Neighbors</h3>
                <div class="preview">
                    <p>
                        Classifying wines using KNN and analyzing the impact of scaling and hyperparameters.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/wine-classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built a K-Nearest Neighbors classifier for the scikit-learn wine dataset, systematically testing K values, distance metrics, and the effect of scaling. Achieved <b>98.15% accuracy</b> with optimal parameters and demonstrated the dramatic impact of feature scaling. Visualizations include K value analysis, confusion matrix, scaling comparison, class distribution, and feature pairplot.
                    </p>
                    <img src="images/wine_classifier/knn_analysis.png" alt="KNN Analysis" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/wine_classifier/confusion_matrix.png" alt="Confusion Matrix" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/wine_classifier/scaling_comparison.png" alt="Scaling Comparison" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/wine_classifier/class_distribution.png" alt="Class Distribution" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/wine_classifier/feature_pairplot.png" alt="Feature Pairplot" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: scikit-learn wine (178 samples, 13 features, 3 classes)</li>
                        <li>Techniques: KNN, scaling, cross-validation, feature analysis</li>
                        <li>Key learning: Scaling is critical for distance-based algorithms</li>
                    </ul>
                    <strong>What I learned:</strong> Proper scaling and parameter tuning are essential for KNN success.
                    <a href="https://github.com/Ivan-Koptiev/wine-classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Deep Q-Network (DQN) for Acrobot -->
            <div class="project-card">
                <h3>Deep Q-Network (DQN) for Acrobot</h3>
                <div class="preview">
                    <p>
                        A PyTorch DQN agent that solves the Acrobot-v1 environment using deep reinforcement learning.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/Acrobat-DQN" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    This project implements a Deep Q-Network (DQN) agent to solve the Acrobot-v1 control problem. The agent uses a three-layer neural network, experience replay, and target networks to achieve the solved threshold of -99.83 average reward. Key insights include the importance of balanced architecture, patient exploration, and training stability techniques like gradient clipping.
                    </p>
                    <img src="images/RL_DQN/dqn_training_visualization.png" alt="DQN Training Visualization" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Environment: Acrobot-v1 (double pendulum)</li>
                        <li>Network: 6 → 64 → 64 → 32 → 3</li>
                        <li>Best average reward: <b>-99.83</b> (solved!)</li>
                        <li>Key features: experience replay, target networks, gradient clipping</li>
                    </ul>
                    <strong>What I learned:</strong> The right network size, slow epsilon decay, and training stability are crucial for RL success.
                    <a href="https://github.com/Ivan-Koptiev/Acrobat-DQN" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: DBSCAN Clustering on Iris Dataset -->
            <div class="project-card">
                <h3>DBSCAN Clustering on Iris Dataset</h3>
                <div class="preview">
                    <p>
                        Density-based clustering on the Iris dataset with DBSCAN, including parameter optimization and rich visualizations.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/DBSCAN_iris" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Explores unsupervised learning with DBSCAN on the classic Iris dataset. The project features automated epsilon selection using the elbow method, comprehensive cluster visualizations, and a direct comparison to true species labels. Results include multi-dimensional plots, cluster statistics, and insights into noise handling and parameter tuning.
                    </p>
                    <img src="images/DBSCAN/elbow_curve.png" alt="Elbow Curve for Epsilon Selection" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/DBSCAN/iris_clustering.png" alt="Iris Clustering Visualization" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Automated epsilon selection (elbow method)</li>
                        <li>Clustered Iris data into 2 groups + noise</li>
                        <li>Visual comparison to true species labels</li>
                        <li>Learned about density-based clustering, parameter tuning, and noise handling</li>
                    </ul>
                    <strong>Optimal epsilon:</strong> 1.108<br>
                    <strong>Clusters found:</strong> 2<br>
                    <strong>Noise points:</strong> 1<br>
                    <a href="https://github.com/Ivan-Koptiev/DBSCAN_iris" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Text Classification with Naive Bayes (20 Newsgroups) -->
            <div class="project-card">
                <h3>Text Classification with Naive Bayes (20 Newsgroups)</h3>
                <div class="preview">
                    <p>
                        Classifying news articles into four categories using TF-IDF and Naive Bayes.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/naive-bayes-text_classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built a text classification pipeline for the 20 Newsgroups dataset using TF-IDF features and Multinomial Naive Bayes. The model achieved <b>91.2% accuracy</b> and provided insights into class separability and feature importance. Visualizations include class distribution, confusion matrix, and top words per class.
                    </p>
                    <img src="images/Naive_bayes/class_distribution.png" alt="Class Distribution" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Naive_bayes/confusion_matrix.png" alt="Confusion Matrix" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Naive_bayes/feature_importance.png" alt="Feature Importance" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: 20 Newsgroups (4 categories)</li>
                        <li>Techniques: TF-IDF, n-grams, feature importance analysis</li>
                        <li>Key learning: Text preprocessing and feature engineering are critical for NLP</li>
                    </ul>
                    <strong>What I learned:</strong> TF-IDF and n-grams enable strong performance on real-world text data.
                    <a href="https://github.com/Ivan-Koptiev/naive-bayes-text_classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Natural Language Processing with BERT -->
            <div class="project-card">
                <h3>Natural Language Processing with BERT</h3>
                <div class="preview">
                    <p>
                        Fine-tuning BERT for sentiment classification and question answering on real-world text.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/BERT-Sentiment" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    This project demonstrates BERT for text classification and question answering, including fine-tuning on a real sentiment dataset. The model predicts sentiment for new texts and answers questions using transfer learning. Demo predictions and a bar plot of sentiment counts are included.
                    </p>
                    <img src="images/NLP_Bert/demo_sentiment_counts.png" alt="Demo Sentiment Counts" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: Tweets labeled as positive/negative</li>
                        <li>Outputs: Sentiment predictions, demo bar plot, question answering</li>
                        <li>Validation accuracy: <b>0.81</b></li>
                        <li>Learned about BERT fine-tuning, evaluation, and inference on new examples</li>
                    </ul>
                    <strong>What I learned:</strong> BERT's transfer learning enables strong results on custom NLP tasks, and early stopping helps avoid overfitting.
                    <a href="https://github.com/Ivan-Koptiev/BERT-Sentiment" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: GAN for Fashion MNIST (TensorFlow) -->
            <div class="project-card">
                <h3>GAN for Fashion MNIST (TensorFlow)</h3>
                <div class="preview">
                    <p>
                        Generating realistic clothing images with a custom GAN trained on Fashion MNIST.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/GAN-fashion-mnist" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built a deep convolutional GAN from scratch in TensorFlow to generate images of clothing items. The project features a custom training loop, TPU acceleration for fast training, and a streamlined architecture for efficiency. Final results include high-quality generated images and a clear adversarial training dynamic.
                    </p>
                    <img src="images/GAN_tf_mnist/final_generated_images.png" alt="Final Generated Images" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/GAN_tf_mnist/training_loss.png" alt="Training Loss" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: Fashion MNIST (28x28 grayscale images)</li>
                        <li>Techniques: Custom GAN, mixed precision, TPU acceleration</li>
                        <li>Key learning: Adversarial training and performance optimization</li>
                    </ul>
                    <strong>What I learned:</strong> Efficient GAN training and debugging with custom callbacks and cloud TPUs.
                    <a href="https://github.com/Ivan-Koptiev/GAN-fashion-mnist" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Car Evaluation with Random Forests -->
            <div class="project-card">
                <h3>Car Evaluation with Random Forests</h3>
                <div class="preview">
                    <p>
                        Predicting car acceptability using Random Forests and categorical feature encoding.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/Car-Evaluation-Random-Forest" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Used a Random Forest classifier to predict car acceptability from categorical features in the UCI Car Evaluation dataset. The project includes ordinal encoding, stratified splitting, and detailed hyperparameter tuning with validation curves. Visualizations highlight class distribution, validation curves, confusion matrix, and feature importance.
                    </p>
                    <img src="images/Car Evaluation Random Forest/class_distribution.png" alt="Class Distribution" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Car Evaluation Random Forest/validation_curve_n_estimators.png" alt="Validation Curve n_estimators" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Car Evaluation Random Forest/validation_curve_max_depth.png" alt="Validation Curve max_depth" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Car Evaluation Random Forest/validation_curve_min_samples_split.png" alt="Validation Curve min_samples_split" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Car Evaluation Random Forest/confusion_matrix.png" alt="Confusion Matrix" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Car Evaluation Random Forest/feature_importance.png" alt="Feature Importance" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: UCI Car Evaluation (categorical features)</li>
                        <li>Techniques: Ordinal encoding, Random Forest, validation curves, feature importance</li>
                        <li>Key learning: Hyperparameter tuning and feature analysis are critical for model performance</li>
                    </ul>
                    <strong>What I learned:</strong> Careful encoding and tuning are essential for categorical data modeling.
                    <a href="https://github.com/Ivan-Koptiev/Car-Evaluation-Random-Forest" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Advanced Spam Detection Pipeline -->
            <div class="project-card">
                <h3>Advanced Spam Detection Pipeline</h3>
                <div class="preview">
                    <p>
                        Detecting spam with advanced feature engineering and model comparison.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/bag-of-words-spam-classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built a robust spam detection pipeline with text preprocessing, feature engineering, and multiple vectorization techniques. Compared Naive Bayes, Logistic Regression, and Random Forest classifiers. Naive Bayes with CountVectorizer achieved <b>98.7% accuracy</b> on the test set. Visualizations include model performance, confusion matrix, and word frequency analysis.
                    </p>
                    <img src="images/Bag-of-words spam classification/spam_classification_results.png" alt="Classification Results" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/Bag-of-words spam classification/spam_ham_word_frequency.png" alt="Word Frequency" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: spam.csv (SMS spam/ham messages)</li>
                        <li>Techniques: Feature engineering, CountVectorizer, TfidfVectorizer, model comparison</li>
                        <li>Key learning: Simpler models can outperform complex ones for text classification</li>
                    </ul>
                    <strong>What I learned:</strong> Feature engineering and model comparison are crucial for robust spam detection.
                    <a href="https://github.com/Ivan-Koptiev/bag-of-words-spam-classification" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Decision Tree for Drug Classification -->
            <div class="project-card">
                <h3>Decision Tree for Drug Classification</h3>
                <div class="preview">
                    <p>
                        Interpretable drug prediction using a decision tree and patient health metrics.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/decision-tree-drug" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built and visualized a decision tree classifier to predict the best drug for a patient based on health metrics. The model achieved <b>97.5% accuracy</b> and provides clear, rule-based predictions. Visualizations include feature importance, confusion matrix, and the full decision tree.
                    </p>
                    <img src="images/decision_tree_drug/feature_importance.png" alt="Feature Importance" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/decision_tree_drug/confusion_matrix.png" alt="Confusion Matrix" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/decision_tree_drug/decision_tree.png" alt="Decision Tree" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: drug200.csv (patient health metrics)</li>
                        <li>Techniques: Categorical encoding, decision tree, visualization</li>
                        <li>Key learning: Decision trees offer interpretability and strong performance</li>
                    </ul>
                    <strong>What I learned:</strong> Decision trees provide transparent, accurate predictions for healthcare data.
                    <a href="https://github.com/Ivan-Koptiev/decision-tree-drug" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: Flowers Classification with CNNs -->
            <div class="project-card">
                <h3>Flowers Classification with CNNs</h3>
                <div class="preview">
                    <p>
                        Classifying five types of flowers using a custom CNN with data augmentation and visualization.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/CNN_flowers" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Built and trained a convolutional neural network to classify images of roses, daisies, dandelions, sunflowers, and tulips. The pipeline includes automated data loading, preprocessing, and extensive data augmentation to improve generalization. The model achieved <b>91.2% accuracy</b> on the training set and <b>73.6% validation accuracy</b>.
                    </p>
                    <img src="images/CNN_flower/model_performance.png" alt="Model Performance" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/CNN_flower/predictions.png" alt="Predictions Grid" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: 3,670 images, 5 flower species</li>
                        <li>Techniques: Data augmentation, dropout, normalization</li>
                        <li>Key learning: End-to-end image classification pipeline and the impact of augmentation</li>
                    </ul>
                    <strong>What I learned:</strong> Data augmentation and careful preprocessing are crucial for robust image classification.
                    <a href="https://github.com/Ivan-Koptiev/CNN_flowers" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

            <!-- Project: K-Means Customer Segmentation -->
            <div class="project-card">
                <h3>K-Means Customer Segmentation</h3>
                <div class="preview">
                    <p>
                        Segmenting retail customers using RFM analysis and K-Means clustering.
                    </p>
                    <a href="https://github.com/Ivan-Koptiev/k-means-retail" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
                <div class="full-description" style="display:none;">
                    <p><strong>Summary:</strong><br>
                    Applied RFM (Recency, Frequency, Monetary) analysis and K-Means clustering to segment retail customers into four distinct groups. The project features robust preprocessing, outlier removal, and comprehensive visualizations. Key business insights include identifying high-value, loyal, at-risk, and occasional customers.
                    </p>
                    <img src="images/K_means_segment/elbow_curve.png" alt="Elbow Curve" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/K_means_segment/customer_segmentation.png" alt="Customer Segmentation" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <img src="images/K_means_segment/cluster_characteristics.png" alt="Cluster Characteristics" style="max-width: 100%; margin: 1rem 0; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
                    <ul>
                        <li>Dataset: Online Retail (4,293 customers, 3 RFM features)</li>
                        <li>Techniques: RFM analysis, outlier removal, K-Means, visualization</li>
                        <li>Key learning: Translating clustering results into actionable business insights</li>
                    </ul>
                    <strong>What I learned:</strong> RFM analysis and clustering are powerful tools for customer segmentation and marketing.
                    <a href="https://github.com/Ivan-Koptiev/k-means-retail" target="_blank" class="project-link"><i class="fab fa-github"></i>View on GitHub</a>
                </div>
            </div>

        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact">
        <div class="contact-content">
            <h2>Contact</h2>
            <div class="contact-info">
                <p><i class="fas fa-map-marker-alt"></i> Rhode Island, USA</p>
                <p><i class="fas fa-envelope"></i> koptew.ivan@gmail.com</p>
            </div>

            <form class="contact-form" method="POST" action="https://formspree.io/f/manegqva">
                <input type="hidden" name="_formname" value="Contact Form">
                <div class="form-group">
                    <label for="name">Name</label>
                    <input type="text" id="name" name="name" required>
                </div>
                <div class="form-group">
                    <label for="email">Email</label>
                    <input type="email" id="email" name="email" required>
                </div>
                <div class="form-group">
                    <label for="message">Message</label>
                    <textarea id="message" name="message" rows="5" required></textarea>
                </div>
                <button type="submit" class="submit-btn">Send Message</button>
                <div id="form-success"
                    style="display:none; color: var(--primary-color); font-weight: 600; margin-top: 1rem;">Thank you!
                    Your message has been sent.</div>
            </form>
            <div class="social-links">
                <a href="https://www.linkedin.com/in/ivan-koptiev-87ab1a298/" target="_blank" rel="noopener noreferrer" class="profile-social-btn linkedin" title="LinkedIn Profile">
                    <i class="fab fa-linkedin"></i>LinkedIn
                </a>
                <a href="https://github.com/Ivan-Koptiev" target="_blank" rel="noopener noreferrer" class="profile-social-btn github" title="GitHub Profile">
                    <i class="fab fa-github"></i>GitHub
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <p style="color:black;"><strong>&copy; 2025 Ivan Koptiev. All rights reserved.</strong></p>
    </footer>

    <script>
        // Function to create modal for a project card
        function createModal(card) {
            const modal = document.createElement('div');
            modal.className = 'modal';

            const modalContent = document.createElement('div');
            modalContent.className = 'modal-content';

            const closeButton = document.createElement('button');
            closeButton.className = 'close-modal';
            closeButton.innerHTML = '×';
            closeButton.style.top = '2.5rem';
            closeButton.onclick = () => {
                modal.style.display = 'none';
                document.body.classList.remove('modal-open');
            };

            // Clone the full description and code from the card
            const fullDescription = card.querySelector('.full-description')?.cloneNode(true);
            const codeBlock = card.querySelector('pre')?.cloneNode(true);
            const title = card.querySelector('h3')?.cloneNode(true);

            // Modal content: Title, full description, code
            if (title) modalContent.appendChild(title);
            if (fullDescription) {
                fullDescription.style.display = 'block';
                modalContent.appendChild(fullDescription);
            }
            if (codeBlock) modalContent.appendChild(codeBlock);

            modalContent.appendChild(closeButton);
            modal.appendChild(modalContent);

            // Close modal when clicking outside
            modal.onclick = (e) => {
                if (e.target === modal) {
                    modal.style.display = 'none';
                    document.body.classList.remove('modal-open');
                }
            };

            return modal;
        }

        // Initialize modals for all project cards
        function setupProjectModals() {
            const projectCards = document.querySelectorAll('.project-card');
            projectCards.forEach(card => {
                const modal = createModal(card);
                document.body.appendChild(modal);
                card.onclick = (e) => {
                    if (e.target.closest('.project-link')) return;
                    modal.style.display = 'block';
                    document.body.classList.add('modal-open');
                };
            });
        }

        // Show a small site-wide tip once about clicking cards
        function showSiteTipOnce() {
            const TIP_KEY = 'dismissedCardTipV1';
            if (localStorage.getItem(TIP_KEY) === '1') return;

            const tip = document.createElement('div');
            tip.className = 'site-tip';
            tip.innerHTML = `
                <div class="site-tip-content">
                    <span class="site-tip-text">Tip: Click any project or experience card to see full details. Press Esc to close.</span>
                    <div class="site-tip-actions">
                        <button class="site-tip-btn">Got it</button>
                        <button class="site-tip-close" aria-label="Close tip">×</button>
                    </div>
                </div>
            `;
            document.body.appendChild(tip);
            const dismiss = () => {
                tip.style.opacity = '0';
                setTimeout(() => tip.remove(), 220);
                localStorage.setItem(TIP_KEY, '1');
            };
            tip.querySelector('.site-tip-btn')?.addEventListener('click', dismiss);
            tip.querySelector('.site-tip-close')?.addEventListener('click', dismiss);
        }

        document.addEventListener('DOMContentLoaded', () => {
            setupProjectModals();
            showSiteTipOnce();
        });

        // Close modal with Escape key
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape') {
                const modals = document.querySelectorAll('.modal');
                modals.forEach(modal => modal.style.display = 'none');
                document.body.classList.remove('modal-open');
            }
        });
    </script>

    <style>
    .modal-open .sticky-nav {
        display: none !important;
    }
    .close-modal {
        top: 2.5rem !important;
    }
    </style>
</body>

</html>
